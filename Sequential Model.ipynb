{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Model (RNN, LSTM)\n",
    "\n",
    "***Dapeng Shang, BU Questrom***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p10.png\" width=\"600\" height=\"200\">\n",
    "</div>\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "&h = 0 \\\\\n",
    "&\\text{for } x \\text{ in } X: \\\\\n",
    "&\\quad h = linear(x, h) \\\\\n",
    "&\\quad h = tanh(h) \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN Cell\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p11.png\" width=\"600\" height=\"200\">\n",
    "</div>\n",
    "\n",
    "$$ h_t = tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{t-1} + b_{hh})$$\n",
    "\n",
    "```python\n",
    "cell = torch.nn.RNNCell(input_size, hidden_size)\n",
    "hidden = cell(input, hidden)\n",
    "```\n",
    "**Input** :\n",
    "input of shape (batch, input_size); hidden of shape (batch, hidden_size)\n",
    "\n",
    "**Output** : hidden of shape (batch, hidden_size)\n",
    "\n",
    "**dataset.shape = (batch, seq_len, input_size)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "hidden size: torch.Size([1, 2])\n",
      "tensor([[-0.1594,  0.7914]], grad_fn=<TanhBackward0>)\n",
      "==================== 1 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "hidden size: torch.Size([1, 2])\n",
      "tensor([[-0.8924,  0.0662]], grad_fn=<TanhBackward0>)\n",
      "==================== 2 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "hidden size: torch.Size([1, 2])\n",
      "tensor([[-0.8680,  0.1673]], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size =1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "\n",
    "cell = torch.nn.RNNCell(input_size, hidden_size)\n",
    "\n",
    "dataset = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(batch_size, hidden_size)\n",
    "\n",
    "for idx, input in enumerate(dataset):\n",
    "    print('='*20, idx, '='*20)\n",
    "    print('Input size:', input.shape)\n",
    "\n",
    "    hidden = cell(input, hidden)\n",
    "\n",
    "    print('hidden size:', hidden.shape)\n",
    "    print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using RNN\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p12.png\" width=\"600\" height=\"200\">\n",
    "</div>\n",
    "\n",
    "```python\n",
    "cell = torch.nn.RNN(input_size, hidden_size, num_layers)\n",
    "out, hidden = cell(input, hidden)\n",
    "```\n",
    "**Input** :\n",
    "input of shape (seqSize, batch, input_size); hidden of shape (numLayers, batch, hidden_size)\n",
    "\n",
    "**Output** : output of shape (seqSize, batch, hidden_size); hidden of shape (numLayers, batch, hidden_size)\n",
    "\n",
    "**numLayers**\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p13.png\" width=\"600\" height=\"200\">\n",
    "</div>\n",
    "\n",
    "**batch_first**: if True, input and output tensors are provided as **(batch, seqSize, input_size)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([3, 1, 2])\n",
      "Output: tensor([[[-0.6445, -0.6960]],\n",
      "\n",
      "        [[ 0.2711,  0.0168]],\n",
      "\n",
      "        [[-0.6503, -0.5252]]], grad_fn=<StackBackward0>)\n",
      "Hidden size: torch.Size([2, 1, 2])\n",
      "Hidden: tensor([[[ 0.2277,  0.7334]],\n",
      "\n",
      "        [[-0.6503, -0.5252]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size =1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 2\n",
    "\n",
    "cell = torch.nn.RNN(input_size, hidden_size, num_layers)\n",
    "\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "out, hidden = cell(inputs, hidden)\n",
    "\n",
    "print('Output size:', out.shape)\n",
    "print('Output:', out)\n",
    "print('Hidden size:', hidden.shape)\n",
    "print('Hidden:', hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: \"hello\" $\\to$ \"ohlol\"\n",
    "\n",
    "##### Using RNN Cell\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p14.png\" width=\"600\" height=\"250\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p15.png\" width=\"600\" height=\"250\">\n",
    "</div>\n",
    "\n",
    "Inputsize/Outputsize = 4: as we have 4 letters in the alphabet (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "# Building a dictionary\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1,0,2,2,3] # hello\n",
    "y_data = [3,1,2,3,2] # ohlol\n",
    "\n",
    "one_hot_lookup = [[1,0,0,0], # 0\n",
    "                  [0,1,0,0], # 1\n",
    "                  [0,0,1,0], # 2\n",
    "                  [0,0,0,1]] # 3\n",
    "# Convert indices to one-hot vector\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "# input dim: (seq_len, batch, input_size)\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
    "# labels dim: (seq_len, 1)\n",
    "labels = torch.LongTensor(y_data).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnncell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.rnncell(input, hidden)\n",
    "        return hidden\n",
    "    \n",
    "    # provide intial hidden h_0\n",
    "    def init_hidden(self):\n",
    "        # batch_size only used in h_0\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "    \n",
    "model = Model(input_size, hidden_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:lllll, Epoch [1/15] loss=6.9622\n",
      "Predicted string:lllll, Epoch [2/15] loss=5.9980\n",
      "Predicted string:lhlll, Epoch [3/15] loss=5.1600\n",
      "Predicted string:lhlol, Epoch [4/15] loss=4.3704\n",
      "Predicted string:lhlol, Epoch [5/15] loss=3.8832\n",
      "Predicted string:ohlol, Epoch [6/15] loss=3.5548\n",
      "Predicted string:ohlol, Epoch [7/15] loss=3.2252\n",
      "Predicted string:ohlol, Epoch [8/15] loss=2.9380\n",
      "Predicted string:ohlol, Epoch [9/15] loss=2.7180\n",
      "Predicted string:ohlol, Epoch [10/15] loss=2.5496\n",
      "Predicted string:ohlol, Epoch [11/15] loss=2.4173\n",
      "Predicted string:ohlol, Epoch [12/15] loss=2.3090\n",
      "Predicted string:ohlol, Epoch [13/15] loss=2.2165\n",
      "Predicted string:ohlol, Epoch [14/15] loss=2.1375\n",
      "Predicted string:ohlol, Epoch [15/15] loss=2.0754\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    print('Predicted string:', end='')\n",
    "    # Loop through the whole sequence\n",
    "    # shape of input: (batch_size, input_size); \n",
    "    # shape of inputs: (seq_len, batch_size, input_size)\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden = model(input, hidden)\n",
    "        # Loss along the sequence should be accumulated \n",
    "        # to construct computational graph\n",
    "        loss += criterion(hidden, label)\n",
    "        # output prediction\n",
    "        _, idx = hidden.max(dim=1)\n",
    "        print(idx2char[idx.item()], end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "\n",
    "\n",
    "# Building a dictionary\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1,0,2,2,3] # hello\n",
    "y_data = [3,1,2,3,2] # ohlol\n",
    "\n",
    "one_hot_lookup = [[1,0,0,0], # 0\n",
    "                  [0,1,0,0], # 1\n",
    "                  [0,0,1,0], # 2\n",
    "                  [0,0,0,1]] # 3\n",
    "# Convert indices to one-hot vector\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size, input_size)\n",
    "# labels dim: (seq_len*batch_size, 1)\n",
    "labels = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = torch.nn.RNN(input_size=self.input_size, \n",
    "                                    hidden_size=self.hidden_size,\n",
    "                                    num_layers=self.num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # inital hidden h_0\n",
    "        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
    "        # don't need to record hidden state\n",
    "        out, _ = self.rnn(input, hidden)\n",
    "        # reshape out to (batch_size*seq_len, hidden_size) to match input dim\n",
    "        return out.view(-1, self.hidden_size)\n",
    "    \n",
    "model = Model(input_size, hidden_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: olooe, Epoch [1/15] loss=1.3778\n",
      "Predicted: olool, Epoch [2/15] loss=1.1973\n",
      "Predicted: ollll, Epoch [3/15] loss=1.0821\n",
      "Predicted: ollll, Epoch [4/15] loss=0.9964\n",
      "Predicted: ololl, Epoch [5/15] loss=0.9237\n",
      "Predicted: oholl, Epoch [6/15] loss=0.8513\n",
      "Predicted: oholl, Epoch [7/15] loss=0.7763\n",
      "Predicted: oholl, Epoch [8/15] loss=0.7238\n",
      "Predicted: ohool, Epoch [9/15] loss=0.6927\n",
      "Predicted: ohool, Epoch [10/15] loss=0.6604\n",
      "Predicted: ohool, Epoch [11/15] loss=0.6342\n",
      "Predicted: ohool, Epoch [12/15] loss=0.6163\n",
      "Predicted: ohool, Epoch [13/15] loss=0.6030\n",
      "Predicted: ohool, Epoch [14/15] loss=0.5916\n",
      "Predicted: ohool, Epoch [15/15] loss=0.5813\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    # inputs dim: (seq_len, batch, input_size), outputs dim: (seq_len, batch, hidden_size)\n",
    "    outputs = model(inputs)\n",
    "    # labels dim: (seq_len, batch, 1)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print('Predicted:', ''.join([idx2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example above, we use **one-hot encoding**\n",
    "1. high-dim\n",
    "2. Sparse\n",
    "3. Hardcoded\n",
    "\n",
    "To solve this, we map from one-hot encoding to low-dim dense vector, i.e. dimension reduction, called **embedding** \n",
    "1. Low-dim\n",
    "2. Dense\n",
    "3. Learn from Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Embedding\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p16.png\" width=\"600\" height=\"300\">\n",
    "</div>\n",
    "\n",
    "```python\n",
    "embedding = torch.nn.Embedding(num_embeddings, embedding_dim)\n",
    "# num_embeddings: size of the dictionary of embeddings\n",
    "# embedding_dim: the size of each embedding vector\n",
    "```\n",
    "**Input** : LongTensor of arbitrary shape containing the indices to extract\n",
    "\n",
    "**Output** : (*, embedding_dim), where * is the input shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 4\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "embedding_size = 10\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(input_size, embedding_size)\n",
    "    \n",
    "        self.rnn = torch.nn.RNN(input_size=embedding_size, \n",
    "                                    hidden_size=hidden_size,\n",
    "                                    num_layers=num_layers,\n",
    "                                    batch_first=True)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_size, num_class)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: (batch_size, seq_len)\n",
    "        hidden = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        # Input LongTensor (batch_size, seq_len), output (batch_size, seq_len, embedding_size)\n",
    "        # Note, batch first\n",
    "        x = self.emb(x)\n",
    "        # Input (batch_size, seq_len, embedding_size), output (batch_size, seq_len, hidden_size)\n",
    "        x, _ = self.rnn(x, hidden)\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, num_class)\n",
    "\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [[1,0,2,2,3]] # (batch, seq_len)\n",
    "y_data = [3,1,2,3,2] # (batch*seq_len)\n",
    "\n",
    "inputs = torch.LongTensor(x_data)\n",
    "labels = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: heeee, Epoch [1/15] loss=1.4693\n",
      "Predicted: oolol, Epoch [2/15] loss=1.1082\n",
      "Predicted: oolol, Epoch [3/15] loss=0.6984\n",
      "Predicted: ohlol, Epoch [4/15] loss=0.4194\n",
      "Predicted: ohlol, Epoch [5/15] loss=0.2707\n",
      "Predicted: ohlol, Epoch [6/15] loss=0.1528\n",
      "Predicted: ohlol, Epoch [7/15] loss=0.0902\n",
      "Predicted: ohlol, Epoch [8/15] loss=0.0540\n",
      "Predicted: ohlol, Epoch [9/15] loss=0.0337\n",
      "Predicted: ohlol, Epoch [10/15] loss=0.0217\n",
      "Predicted: ohlol, Epoch [11/15] loss=0.0142\n",
      "Predicted: ohlol, Epoch [12/15] loss=0.0096\n",
      "Predicted: ohlol, Epoch [13/15] loss=0.0067\n",
      "Predicted: ohlol, Epoch [14/15] loss=0.0048\n",
      "Predicted: ohlol, Epoch [15/15] loss=0.0036\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print('Predicted:', ''.join([idx2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./Asset/p17.png\" width=\"600\" height=\"300\">\n",
    "</div>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&i_t = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi}) \\\\\n",
    "&f_t = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf}) \\\\\n",
    "&g_t = \\tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hg}) \\\\\n",
    "&o_t = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho}) \\\\\n",
    "&c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
    "&h_t = o_t \\odot \\tanh(c_t)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Advantage**: add a direct path for gradient to flow along $c_t$, which can solve the problem of vanishing gradient\n",
    "\n",
    "```python\n",
    "cell = torch.nn.LSTM(input_size, hidden_size, num_layers)\n",
    "out, (h, c) = cell(input, (h, c))\n",
    "```\n",
    "**Input**: input of shape (seqSize, batch, input_size); hidden of shape (numLayers * numDirections, batch, hidden_size); cell of shape (numLayers * numDirections, batch, hidden_size)\n",
    "\n",
    "**Output**: output of shape (seqSize, batch, hidden_size); hidden of shape (numLayers * numDirections, batch, hidden_size); cell of shape (numLayers * numDirections, batch, hidden_size)\n",
    "\n",
    "```python\n",
    "numDirections = 2 if bidirectional else 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "num_class = 4\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "embedding_size = 10\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [[1,0,2,2,3]] # (batch, seq_len)\n",
    "y_data = [3,1,2,3,2] # (batch*seq_len)\n",
    "\n",
    "inputs = torch.LongTensor(x_data)\n",
    "labels = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_layers, bidirectional=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.emb = torch.nn.Embedding(input_size, embedding_size)\n",
    "    \n",
    "        self.lstm = torch.nn.LSTM(input_size=embedding_size, \n",
    "                                    hidden_size=hidden_size,\n",
    "                                    num_layers=num_layers,\n",
    "                                    bidirectional = bidirectional,\n",
    "                                    batch_first=True)\n",
    "        # if bidirectional, hidden_size*2\n",
    "        self.fc = torch.nn.Linear(hidden_size*self.num_directions, num_class)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: (batch_size, seq_len)\n",
    "        hidden = torch.zeros(self.num_layers*self.num_directions, x.size(0), hidden_size)\n",
    "        cell = torch.zeros(self.num_layers*self.num_directions, x.size(0), hidden_size)\n",
    "        # Input LongTensor (batch_size, seq_len), output (batch_size, seq_len, embedding_size)\n",
    "        # Note, batch first\n",
    "        x = self.emb(x)\n",
    "        # Input (batch_size, seq_len, embedding_size), output (batch_size, seq_len, hidden_size)\n",
    "        x, _ = self.lstm(x, (hidden, cell))\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, num_class)\n",
    "\n",
    "    \n",
    "model = Model(num_layers, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: hhhhh, Epoch [1/15] loss=1.3900\n",
      "Predicted: ooooo, Epoch [2/15] loss=1.2025\n",
      "Predicted: ollll, Epoch [3/15] loss=1.0328\n",
      "Predicted: oolll, Epoch [4/15] loss=0.8841\n",
      "Predicted: oholl, Epoch [5/15] loss=0.7371\n",
      "Predicted: ohool, Epoch [6/15] loss=0.5523\n",
      "Predicted: ohlol, Epoch [7/15] loss=0.3412\n",
      "Predicted: ohlol, Epoch [8/15] loss=0.1919\n",
      "Predicted: ohlol, Epoch [9/15] loss=0.0978\n",
      "Predicted: ohlol, Epoch [10/15] loss=0.0518\n",
      "Predicted: ohlol, Epoch [11/15] loss=0.0256\n",
      "Predicted: ohlol, Epoch [12/15] loss=0.0126\n",
      "Predicted: ohlol, Epoch [13/15] loss=0.0068\n",
      "Predicted: ohlol, Epoch [14/15] loss=0.0039\n",
      "Predicted: ohlol, Epoch [15/15] loss=0.0024\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print('Predicted:', ''.join([idx2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
